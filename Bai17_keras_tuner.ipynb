{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bai17. keras_tuner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zonezero2604/Hkr_Set/blob/master/Bai17_keras_tuner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Giới thiệu về Keras Tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Tổng quát\n",
        "\n",
        "Keras Tuner là một thư viện giúp bạn chọn bộ siêu tham số (hyperparameters) tối ưu cho chương trình TensorFlow của mình. Quá trình lựa chọn quyền thiết lập các siêu tham số cho  ứng dụng machine learning (ML) được gọi *hyperparameter tuning* hoặc *hypertuning*. \n",
        "\n",
        "Hyperparameters là các biến chi phối quá trình đào tạo và cấu trúc liên kết của một mô hình ML. Các biến này không đổi trong quá trình đào tạo và ảnh hưởng trực tiếp đến hiệu suất của chương trình ML của bạn. Siêu tham số có hai loại:\n",
        " \n",
        "1. **Model hyperparameters**  của mô hình ảnh hưởng đến việc lựa chọn mô hình chẳng hạn như số lượng và chiều rộng của các lớp ẩn\n",
        "2. **Algorithm hyperparameters** ảnh hưởng đến tốc độ và chất lượng của thuật toán học tập, chẳng hạn như tốc độ học cho Stochastic Gradient Descent (SGD) và số lượng lân cận gần nhất cho ak Nearest Neighbors (KNN)\n",
        "\n",
        "Trong hướng dẫn này, bạn sẽ sử dụng Keras Tuner để thực hiện hypertuning cho ứng dụng phân loại hình ảnh."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqR2PQG4ZaZ0"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import IPython"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g83Lwsy-Aq2_"
      },
      "source": [
        "Cài đặt và import the Keras Tuner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_leAIdFKAxAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "968967be-e07c-4605-e92e-978ac7d67075"
      },
      "source": [
        "!pip install -U keras-tuner\n",
        "import kerastuner as kt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\r\u001b[K     |█████▏                          | 10kB 22.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 21.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.8.9)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->keras-tuner) (1.0.1)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp37-none-any.whl size=78938 sha256=b2653b37d2ea6efa4137313f05d30ff143e66ea41a7c1b62cc5c4e33de090fd4\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=080fa8499c1bb88941a66109cf07b7c92d10b18a5a4448a2589cc06f65630193\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReV_UXOgCZvx"
      },
      "source": [
        "## Download và chuẩn bị tập dữ liệu\n",
        "\n",
        "Trong hướng dẫn này, bạn sẽ sử dụng Keras Tuner để tìm các siêu tham số tốt nhất cho mô hình máy học phân loại hình ảnh quần áo từ [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HljH_ENLEdHa"
      },
      "source": [
        "Load the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHlHs9Wj_PUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6deb36fd-0b31-4a52-a5a6-608402af9ea6"
      },
      "source": [
        "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLVhXs3xrUD0"
      },
      "source": [
        "# Normalize pixel values between 0 and 1\n",
        "img_train = img_train.astype('float32') / 255.0\n",
        "img_test = img_test.astype('float32') / 255.0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5YEL2H2Ax3e"
      },
      "source": [
        "## Define the model\n",
        "\n",
        "Khi bạn xây dựng một mô hình cho hypertuning, bạn cũng xác định không gian tìm kiếm hyperparameter ngoài kiến trúc mô hình. Mô hình bạn thiết lập để tăng cường được gọi là   *hypermodel*.\n",
        "\n",
        "Bạn có thể định nghĩa hypermodel thông qua hai cách tiếp cận:\n",
        "\n",
        "* Bằng cách sử dụng chức năng xây dựng mô hình (model builder function)\n",
        "* Bằng cách phân lớp lớp `HyperModel` của Keras Tuner API\n",
        "\n",
        "Bạn cũng có thể sử dụng hai lớp `HyperModel` - [HyperXception](https://keras-team.github.io/keras-tuner/documentation/hypermodels/#hyperxception-class) và [HyperResNet](https://keras-team.github.io/keras-tuner/documentation/hypermodels/#hyperresnet-class) cho các ứng dụng thị giác máy tính.\n",
        "\n",
        "Trong hướng dẫn này, bạn sử dụng chức năng xây dựng mô hình để định nghĩa mô hình phân loại hình ảnh. Hàm tạo mô hình trả về một mô hình đã biên dịch và sử dụng các hyperparameters mà bạn định nghĩa để hypertune model.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQKodC-jtsva"
      },
      "source": [
        "def model_builder(hp):\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "  \n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "  hp_units1 = hp.Int('units1', min_value = 32, max_value = 512, step = 32)\n",
        "  hp_units2 = hp.Int('units2', min_value = 32, max_value = 512, step = 32)\n",
        "  hp_dropout1 = hp.Float('drop_out1', min_value = 0.0, max_value = 0.5, step = 0.1)\n",
        "  hp_dropout2 = hp.Float('drop_out2', min_value = 0.0, max_value = 0.5, step = 0.1)\n",
        "  model.add(keras.layers.Dense(units = hp_units1, activation = 'relu'))\n",
        "  model.add(keras.layers.Dropout(hp_dropout1))\n",
        "  model.add(keras.layers.Dense(units = hp_units2, activation = 'relu'))\n",
        "  model.add(keras.layers.Dropout(hp_dropout2))\n",
        "  model.add(keras.layers.Dense(10))\n",
        "\n",
        "  # Tune the learning rate for the optimizer \n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
        "  \n",
        "  model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
        "                loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True), \n",
        "                metrics = ['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J1VYw4q3x0b"
      },
      "source": [
        "## Khởi tạo bộ điều chỉnh (tuner) và thực hiệu hypertuning\n",
        "\n",
        "Keras Tuner có 4 bộ điều chỉnh (tuners) - `RandomSearch`, `Hyperband`, `BayesianOptimization`, và `Sklearn`. Trong hướng dẫn này, chúng ta sử dụng bộ chỉnh [Hyperband](https://arxiv.org/pdf/1603.06560.pdf). \n",
        "\n",
        "Để khởi tạo bộ chỉnh Hyperband, bạn phải chỉ định hypermodel, `objective` cần tối ưu hóa và số epochs tối đa để train (`max_epochs`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oichQFly6Y46"
      },
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective = 'val_accuracy', \n",
        "                     max_epochs = 10,\n",
        "                     factor = 3,\n",
        "                     directory = 'my_dir',\n",
        "                     project_name = 'intro_to_kt',\n",
        "                     )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaIhhdKf9VtI"
      },
      "source": [
        "Thuật toán điều chỉnh siêu băng thông (Hyperband tuning algorithm) sử dụng phân bổ tài nguyên thích ứng (adaptive resource allocation) và dừng sớm (early-stopping) để nhanh chóng hội tụ vào một mô hình hiệu suất cao (high-performing model). Điều này được thực hiện bằng cách sử dụng phương pháp kiểu vô địch thể thao.\n",
        "\n",
        "Thuật toán đào tạo một số lượng lớn các mô hình trong một vài epochs và chỉ chuyển tiếp một nửa số mô hình hoạt động tốt nhất sang vòng tiếp theo.\n",
        "\n",
        "Siêu băng tần xác định số lượng mô hình cần đào tạo trong một dải đồng hạng bằng cách tính toán 1 + log<sub>`factor`</sub>(`max_epochs`) và làm tròn nó đến số nguyên gần nhất.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTeamrUWOJRb"
      },
      "source": [
        "Trước khi chạy tìm kiếm siêu tham số, hãy định nghĩa một lệnh callback để xóa kết quả huấn luyện ở cuối mỗi bước huấn luyện. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbr_8QE76PJd"
      },
      "source": [
        "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
        "  def on_train_end(*args, **kwargs):\n",
        "    IPython.display.clear_output(wait = True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKghEo15Tduy"
      },
      "source": [
        "Chạy tìm kiếm siêu tham số. Các đối số cho phương thức tìm kiếm cũng giống như các đối số được sử dụng cho `tf.keras.model.fit` ngoài lệnh callback ở trên. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSBQcTHF9cKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60154cc9-d1bb-498b-9066-f04f9f2e6406"
      },
      "source": [
        "tuner.search(img_train, label_train, epochs = 10, validation_data = (img_test, label_test), callbacks = [ClearTrainingOutput()])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units1')}, the second fc is {best_hps.get('units2')}, the first dropout is {best_hps.get('drop_out1')}\n",
        "the second dropout is {best_hps.get('drop_out2')}\n",
        "and best learning rate is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 30 Complete [00h 00m 40s]\n",
            "val_accuracy: 0.8822000026702881\n",
            "\n",
            "Best val_accuracy So Far: 0.8865000009536743\n",
            "Total elapsed time: 00h 08m 09s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 480, the second fc is 480, the first dropout is 0.30000000000000004\n",
            "the second dropout is 0.4\n",
            "and best learning rate is 0.0001.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lak_ylf88xBv"
      },
      "source": [
        "Để kết thúc hướng dẫn này, hãy đào tạo lại mô hình với các siêu tham số tối ưu vừa tìm kiếm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McO82AXOuxXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c6ded96-7493-4ea5-9731-2b4a96ebae56"
      },
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "model.fit(img_train, label_train, epochs = 10, validation_data = (img_test, label_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.9194 - accuracy: 0.6856 - val_loss: 0.4579 - val_accuracy: 0.8397\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4658 - accuracy: 0.8333 - val_loss: 0.4162 - val_accuracy: 0.8493\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4098 - accuracy: 0.8550 - val_loss: 0.3838 - val_accuracy: 0.8610\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3698 - accuracy: 0.8655 - val_loss: 0.3638 - val_accuracy: 0.8681\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3458 - accuracy: 0.8735 - val_loss: 0.3571 - val_accuracy: 0.8704\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3348 - accuracy: 0.8778 - val_loss: 0.3438 - val_accuracy: 0.8777\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3112 - accuracy: 0.8880 - val_loss: 0.3397 - val_accuracy: 0.8769\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3045 - accuracy: 0.8883 - val_loss: 0.3331 - val_accuracy: 0.8808\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2943 - accuracy: 0.8926 - val_loss: 0.3248 - val_accuracy: 0.8833\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2837 - accuracy: 0.8962 - val_loss: 0.3277 - val_accuracy: 0.8839\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f87ccf6f110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQRpPHZsz-eC"
      },
      "source": [
        "Thư mục `my_dir/intro_to_kt` chứa nhật ký chi tiết và các điểm kiểm tra (checkpoints) cho mỗi lần chạy thử (cấu hình mô hình) chạy trong quá trình tìm kiếm siêu tham số (hyperparameter search).  Nếu bạn chạy lại tìm kiếm siêu tham số, Keras Tuner sử dụng trạng thái hiện có từ các nhật ký này để tiếp tục tìm kiếm. Để vô hiệu hóa hành vi này, hãy truyền một đối số `overwrite = True` trong khi khởi tạo bộ chỉnh (tuner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKwLOzKpFGAj"
      },
      "source": [
        "## Tóm lược\n",
        "\n",
        "Trong hướng dẫn này, bạn đã học cách sử dụng Keras Tuner để điều chỉnh các siêu tham số cho một mô hình. Để tìm hiểu thêm về Keras Tuner, hãy xem các tài nguyên bổ sung sau:\n",
        "\n",
        "* [Keras Tuner on the TensorFlow blog](https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html)\n",
        "* [Keras Tuner website](https://keras-team.github.io/keras-tuner/)\n",
        "\n",
        "Ngoài ra, hãy xem  [HParams Dashboard](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams) trong TensorBoard để điều chỉnh tương tác các hyperparameters của mô hình "
      ]
    }
  ]
}