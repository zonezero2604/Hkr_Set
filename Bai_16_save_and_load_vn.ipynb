{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Bai 16. save_and_load_vn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zonezero2604/Hkr_Set/blob/master/Bai_16_save_and_load_vn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZJ3uY9O17VN"
      },
      "source": [
        "# Save and load models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBdde4YJeJKF"
      },
      "source": [
        "Tiến trình của mô hình có thể được lưu trong — và sau — quá trình đào tạo. Điều này có nghĩa là một mô hình có thể tiếp tục lại khi nó đã dừng lại và tránh thời gian đào tạo dài. Lưu cũng có nghĩa là bạn có thể chia sẻ mô hình của mình và những người khác có thể tạo lại tác phẩm của bạn. Khi xuất bản các mô hình và kỹ thuật nghiên cứu, hầu hết các học viên máy học chia sẻ:\n",
        "\n",
        "* code để tạo mô hình và\n",
        "* Weight hoặc thông số được đào tạo cho mô hình (hyperparametters)\n",
        "\n",
        "Chia sẻ dữ liệu này giúp những người khác hiểu cách hoạt động của mô hình và tự mình thử với dữ liệu mới.\n",
        "\n",
        "Thận trọng: Hãy cẩn thận với mã không đáng tin cậy — Các mô hình TensorFlow là mã. Xem [Sử dụng TensorFlow an toàn](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) để biết chi tiết.\n",
        "\n",
        "### Tùy chọn\n",
        "\n",
        "Có nhiều cách khác nhau để lưu các mô hình TensorFlow — tùy thuộc vào API bạn đang sử dụng. Hướng dẫn này sử dụng [tf.keras](https://www.tensorflow.org/guide/keras), một API cấp cao để xây dựng và đào tạo các mô hình trong TensorFlow. Đối với các phương pháp tiếp cận khác, hãy xem hướng dẫn TensorFlow [Lưu và khôi phục](https://www.tensorflow.org/guide/saved_model) hoặc [lưu trong eager](https://www.tensorflow.org/guide/eager#object-based_saving).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCUREq7WXgvg"
      },
      "source": [
        "## Setup\n",
        "\n",
        "### Installs and imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l0MiTOrXtNv"
      },
      "source": [
        "cài đặt và import TensorFlow và dependencies (các phụ thuộc):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzIOVSdnMYyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c782da61-33d3-46d3-cead-797c42227748"
      },
      "source": [
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nm7Tyb-gRt-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a978d0-93c0-4522-a590-fffd817a6876"
      },
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbGsznErXWt6"
      },
      "source": [
        "### Lấy một tập dữ liệu mẫu\n",
        "\n",
        "Để mô phỏng các save-load weight, bạn sẽ sử dụng [MNIST dataset](http://yann.lecun.com/exdb/mnist/). Để tăng tốc và chạy khỏng 1000 samples đầu tiên:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rGfFwE9XVwz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58204ac1-68bc-4b45-c100-6e60d4e755e6"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_labels = train_labels[:1000]  # chỉ lấy 1 nghìn mẫu để train (ko cần nhiều)\n",
        "test_labels = test_labels[:1000]\n",
        "\n",
        "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
        "test_images  = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anG3iVoXyZGI"
      },
      "source": [
        "### Định nghĩa một model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wynsOBfby0Pa"
      },
      "source": [
        "Bắt đầu bằng cách xây dựng một mô hình tuần tự đơn giản:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HZbJIjxyX1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5486f9ab-f298-48bf-d907-cc7044a3a3e9"
      },
      "source": [
        "# Define a simple sequential model\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(10)\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# Create a basic model instance\n",
        "model = create_model()\n",
        "\n",
        "# Display the model's architecture\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soDE0W_KH8rG"
      },
      "source": [
        "## Lưu checkpoints trong quá trình training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRyd5qQQIXZm"
      },
      "source": [
        "Bạn có thể sử dụng một mô hình đã được đào tạo mà không cần phải đào tạo lại hoặc tiếp tục đào tạo từ nơi bạn đã dừng lại — trong trường hợp quá trình đào tạo bị gián đoạn.\n",
        "Hàm `tf.keras.callbacks.ModelCheckpoint` cho phép bạn lưu mô hình trong và sau quá trình tranning\n",
        "\n",
        "### Sử dụng Checkpoint callback \n",
        "\n",
        "Tạo một hàm `tf.keras.callbacks.ModelCheckpoint` để lưu thông tin training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFPuhwntH8VH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50191bdc-5c97-4f71-8166-c0749c2fd464"
      },
      "source": [
        "# //OK 1:\n",
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "# Train the model with the new callback\n",
        "model.fit(train_images, \n",
        "          train_labels,  \n",
        "          epochs=10,\n",
        "          validation_data=(test_images,test_labels),\n",
        "          callbacks=[cp_callback])  # Pass callback to training\n",
        "\n",
        "# This may generate warnings related to saving the state of the optimizer.\n",
        "# These warnings (and similar warnings throughout this notebook)\n",
        "# are in place to discourage outdated usage, and can be ignored."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 4s 16ms/step - loss: 1.6238 - accuracy: 0.5164 - val_loss: 0.7406 - val_accuracy: 0.7760\n",
            "\n",
            "Epoch 00001: saving model to training_1/cp.ckpt\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.8813 - val_loss: 0.5389 - val_accuracy: 0.8310\n",
            "\n",
            "Epoch 00002: saving model to training_1/cp.ckpt\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.3011 - accuracy: 0.9210 - val_loss: 0.4858 - val_accuracy: 0.8440\n",
            "\n",
            "Epoch 00003: saving model to training_1/cp.ckpt\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.2096 - accuracy: 0.9616 - val_loss: 0.4680 - val_accuracy: 0.8540\n",
            "\n",
            "Epoch 00004: saving model to training_1/cp.ckpt\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1334 - accuracy: 0.9760 - val_loss: 0.4627 - val_accuracy: 0.8540\n",
            "\n",
            "Epoch 00005: saving model to training_1/cp.ckpt\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1276 - accuracy: 0.9672 - val_loss: 0.4974 - val_accuracy: 0.8450\n",
            "\n",
            "Epoch 00006: saving model to training_1/cp.ckpt\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1160 - accuracy: 0.9814 - val_loss: 0.4260 - val_accuracy: 0.8620\n",
            "\n",
            "Epoch 00007: saving model to training_1/cp.ckpt\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9908 - val_loss: 0.4386 - val_accuracy: 0.8550\n",
            "\n",
            "Epoch 00008: saving model to training_1/cp.ckpt\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9925 - val_loss: 0.4423 - val_accuracy: 0.8580\n",
            "\n",
            "Epoch 00009: saving model to training_1/cp.ckpt\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.9986 - val_loss: 0.4199 - val_accuracy: 0.8690\n",
            "\n",
            "Epoch 00010: saving model to training_1/cp.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd0dff89b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlM-sgyJO084"
      },
      "source": [
        "Điều này tạo ra một bộ sưu tập các tệp  TensorFlow checkpoint được cập nhật vào cuối mỗi epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXG5FVKFOVQ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f4f2ba-1521-40cc-e554-1f22c0dea0cd"
      },
      "source": [
        "!ls -la -h {checkpoint_dir}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4.7M\n",
            "drwxr-xr-x 2 root root 4.0K May 24 08:17 .\n",
            "drwxr-xr-x 1 root root 4.0K May 24 08:17 ..\n",
            "-rw-r--r-- 1 root root   71 May 24 08:17 checkpoint\n",
            "-rw-r--r-- 1 root root 4.7M May 24 08:17 cp.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root 1.2K May 24 08:17 cp.ckpt.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlRN_f56Pqa9"
      },
      "source": [
        "Tạo một mô hình mới, chưa qua đào tạo. Khi khôi phục một mô hình từ weight đã lưu, bạn phải có một mô hình có cùng *kiến trúc* với mô hình ban đầu. Khi hai kiến trúc tương đồng, bạn có thể dùng chung weight của các thời điểm training khác nhau.\n",
        "\n",
        "Bây giờ xây dựng tiếp một mô hình mới, chưa được đào tạo và đánh giá nó trên bộ thử nghiệm. Một mô hình chưa được đào tạo sẽ hoạt động ở mức cơ hội (độ chính xác ~ 10%):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp5gbuiaPqCT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b8c2134-e931-4046-e6db-6d6da2c46ee8"
      },
      "source": [
        "# Create a basic model instance\n",
        "model1 = create_model()\n",
        "\n",
        "# Evaluate the model\n",
        "loss, acc = model1.evaluate(test_images,  test_labels, verbose=2)\n",
        "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 2.3301 - accuracy: 0.0900\n",
            "Untrained model, accuracy:  9.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DTKpZssRSo3"
      },
      "source": [
        "Sau đó load weights từ các file checkpoint và đánh giá lại tập test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IZxbwiRRSD2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8088c2-063f-4204-8f60-56328cc5ad3c"
      },
      "source": [
        "# //OK 1: load\n",
        "# Loads the weights\n",
        "model1.load_weights(checkpoint_path)\n",
        "\n",
        "# Re-evaluate the model\n",
        "loss,acc = model1.evaluate(test_images,  test_labels, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 0.4199 - accuracy: 0.8690\n",
            "Restored model, accuracy: 86.90%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpAbKkAyVPV8"
      },
      "source": [
        "### Các tùy chọn Checkpoint callback \n",
        "\n",
        "Checkpoint cho phép đặt các tùy chọn sao cho tên file sẽ được lưu là duy nhất cho mỗi lần lưu trữ, điều này giúp cho chúng ta chọn được weight có giá trị tốt nhất sau quá trình training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwxmuoEvZFlp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90d89397-13bc-434e-c5d3-89fecf30f63e"
      },
      "source": [
        "!rm /content/training_2/*\n",
        "!rm -d /content/training_2\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/training_2/*': No such file or directory\n",
            "rm: cannot remove '/content/training_2': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVIrrBh8X8m4"
      },
      "source": [
        "tf.keras.callbacks.ModelCheckpoint??"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQF_dlgIVOvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b95b1818-a236-4701-f717-992ea8ad6b37"
      },
      "source": [
        "# OK 2: save\n",
        "# Include the epoch in the file name (uses `str.format`)\n",
        "checkpoint_path = \"training_2/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights every 5 epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    save_best_only=True\n",
        "    )\n",
        "\n",
        "# Create a new model instance\n",
        "model = create_model()\n",
        "\n",
        "# Save the weights using the `checkpoint_path` format\n",
        "model.save_weights(checkpoint_path.format(epoch=0))\n",
        "\n",
        "# Train the model with the new callback\n",
        "model.fit(train_images, \n",
        "          train_labels,\n",
        "          epochs=50, \n",
        "        #   steps_per_epoch=1,\n",
        "          callbacks=[cp_callback],\n",
        "          validation_data=(test_images,test_labels),\n",
        "          verbose=0)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.73543, saving model to training_2/cp.ckpt\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.73543 to 0.55148, saving model to training_2/cp.ckpt\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.55148 to 0.50379, saving model to training_2/cp.ckpt\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.50379 to 0.44122, saving model to training_2/cp.ckpt\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.44122 to 0.41914, saving model to training_2/cp.ckpt\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.41914 to 0.41833, saving model to training_2/cp.ckpt\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.41833\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.41833 to 0.41166, saving model to training_2/cp.ckpt\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.41166\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.41166 to 0.40388, saving model to training_2/cp.ckpt\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.40388\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.40388 to 0.40345, saving model to training_2/cp.ckpt\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.40345\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.40345\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.40345\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.40345 to 0.39585, saving model to training_2/cp.ckpt\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.39585\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.39585\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd058114d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zFrKTjjavWI"
      },
      "source": [
        "Bây giờ, hãy xem các checkpoint và chọn checkpoint mới nhất:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p64q3-V4sXt0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b0c7965-e3aa-48cd-b897-558c43d5900a"
      },
      "source": [
        "!ls -la -h {checkpoint_dir}"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4.7M\n",
            "drwxr-xr-x 2 root root 4.0K May 24 08:17 .\n",
            "drwxr-xr-x 1 root root 4.0K May 24 08:17 ..\n",
            "-rw-r--r-- 1 root root   71 May 24 08:17 checkpoint\n",
            "-rw-r--r-- 1 root root 4.7M May 24 08:17 cp.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root 1.2K May 24 08:17 cp.ckpt.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AN_fnuyR41H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9d677714-5f36-49d3-c61e-220da5dade6d"
      },
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "latest"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'training_2/cp.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk2ciGbKg561"
      },
      "source": [
        "Lưu ý: định dạng tensorflow mặc định chỉ lưu 5 checkpoints gần nhất.\n",
        "Để test, hãy reset model và thực hiện dự đoán:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M04jyK-H3QK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c6d855-69ca-46a2-b4da-574688b0c214"
      },
      "source": [
        "# OK 2: Load\n",
        "# Create a new model instance\n",
        "model2 = create_model()\n",
        "\n",
        "# Load the previously saved weights\n",
        "model2.load_weights(latest)\n",
        "\n",
        "# Re-evaluate the model\n",
        "loss, acc = model2.evaluate(test_images,  test_labels, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 0.3958 - accuracy: 0.8750\n",
            "Restored model, accuracy: 87.50%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2OxsJOTHxia"
      },
      "source": [
        "## Những tệp này là gì?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtdYhvWnH2ib"
      },
      "source": [
        "Các đoạn code trên lưu các weight vào các tệp [checkpoint](https://www.tensorflow.org/guide/saved_model#save_and_restore_variables)-các file checkpoint chứa các thông tin:\n",
        "* Một hoặc nhiều phân đoạn chứa trọng số của mô hình.\n",
        "* một file index chỉ ra weights nào được lưu trữ trong phân đoạn nào.\n",
        "\n",
        "Nếu bạn chỉ đào tạo một mô hình trên một máy duy nhất, bạn sẽ có một phân đoạn với hậu tố: `.data-00000-of-00001`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_FA-ZvxuXQV"
      },
      "source": [
        "## Lưu trọng số theo cách thủ công\n",
        "\n",
        "Lưu trọng số bằng cách dùng lệnh `Model.save_weights`. Mặc định, `tf.keras`— và `save_weights` sử dụng checkpoint với đuôi `.ckpt`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7W5plyZ-u9X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e33e5ad-4250-40bd-f0d9-59c079ce40e1"
      },
      "source": [
        "# OK 3: Save & Load\n",
        "# Save the weights\n",
        "model2.save_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "# Create a new model instance\n",
        "model3 = create_model()\n",
        "\n",
        "# Restore the weights\n",
        "model3.load_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "# Evaluate the model\n",
        "loss,acc = model3.evaluate(test_images,  test_labels, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 0.3958 - accuracy: 0.8750\n",
            "Restored model, accuracy: 87.50%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOGlxPRBEvV1"
      },
      "source": [
        "## Lưu toàn bộ mô hình (cả model+weight)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rQqjklBvcci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65a30e2c-b9cc-4094-91f3-2f33717e9282"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import model_from_json\n",
        "import numpy\n",
        "import os\n",
        "from os.path import exists\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(211)\n",
        "# load pima indians dataset\n",
        "Pdata='pima-indians-diabetes.data.csv'\n",
        "if not exists(Pdata):\n",
        "    !wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\n",
        "\n",
        "dataset = numpy.loadtxt(Pdata, delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y, verbose=0)\n",
        "print(\"1st: %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        " \n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        " \n",
        "# later...\n",
        " \n",
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X, Y, verbose=0)\n",
        "print(\"2nd: %s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-24 08:17:36--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23278 (23K) [text/plain]\n",
            "Saving to: ‘pima-indians-diabetes.data.csv’\n",
            "\n",
            "\r          pima-indi   0%[                    ]       0  --.-KB/s               \rpima-indians-diabet 100%[===================>]  22.73K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-24 08:17:36 (125 MB/s) - ‘pima-indians-diabetes.data.csv’ saved [23278/23278]\n",
            "\n",
            "1st: accuracy: 78.39%\n",
            "Saved model to disk\n",
            "Loaded model from disk\n",
            "2nd: accuracy: 78.39%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxfRrciQXSL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3610e10f-915a-4543-90ea-b99c7b004ae1"
      },
      "source": [
        "X"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8EkOE8rvcR0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "37359b5d-8247-4b5d-f2d2-78063b219127"
      },
      "source": [
        "loaded_model_json"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_5\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 8], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"dense_10_input\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_10\", \"trainable\": true, \"batch_input_shape\": [null, 8], \"dtype\": \"float32\", \"units\": 12, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_11\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 8, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_12\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.4.0\", \"backend\": \"tensorflow\"}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}